# -*- coding: utf-8 -*-
"""AI_part1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wJ0189VNhht4MEGDODkA_A9m9Jrbrw8K
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torchvision.transforms.transforms import Normalize
from sklearn.model_selection import train_test_split 
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from operator import truediv
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sn
import pandas as pd
import math
import warnings
warnings.filterwarnings("ignore")

"""*Pre processing of data by applying various transformation*"""

img_reshape = transforms.Resize((64,64)) #resizes input image to the given size 
img_to_tensor = torchvision.transforms.ToTensor()#converts image to tensor 
img_normalization = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #normalizes image with mean and standard deviation
#normalize the image to make it look better to visualize and 
#to make computation efficient by reducing values between 0 to 1 
transform = transforms.Compose([img_reshape,img_to_tensor,img_normalization])#composes/chaining several transforms together

"""*Loading dataset and splitting training and tetsing data*"""

dataset = ImageFolder(root = "/content/drive/MyDrive/FINAL_DATASET",transform = transform)
print(dataset)
#dataset stores all the data but we use dataloader to iterate through the data, manage batches and transforming the data.

categories = ('Cloth_Mask', 'N95', 'IncorrectMask', 'Surgical_Mask','Without_Mask')
class_dictionary = {}
for i in range(len(dataset.classes)):
    class_dictionary[categories[i]] = 0

for i in range(len(dataset)):
    img, img_label = dataset[i]
    class_dictionary[categories[img_label]] += 1

Keylist =  list(class_dictionary.keys())
valuelist = list(class_dictionary.values())
plt.bar(Keylist, valuelist)
plt.xlabel("Dataset Classes")
plt.ylabel("Number of Images")

train_data, test_data = train_test_split(dataset,test_size=0.25, random_state=130)
#dataloader will laod the data with batch size 110 means 110 samples per batch to load, shuffle true to reshuffle data after every epoch 
#so the train loader size will be train_dataset/batch_size = 1493/110 = 14 
train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)
test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=True)

print(len(train_data))
print(len(test_data))
print(len(train_dataloader))
print(len(test_dataloader))

#we will inherit the nn.module for our CNN 
class CNN(nn.Module):
    def __init__(self):
        super().__init__()
        # here we have applied 2D convolutional layer on our input image with several input planes 
        # input size = 3 - three color channels i.e RGB 
        # output size 16 
        # kernel size = 3 does not change further 
        # stride size = 1 remains same 
        self.conv_layer_1 = nn.Sequential(
            nn.Conv2d(3,16,3,1,padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2,2)
            
            
        )
        self.conv_layer_2 = nn.Sequential(
            nn.Conv2d(16,32,3,1,padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2,2)
            
        )
        self.conv_layer_3 = nn.Sequential(
            nn.Conv2d(32,64,3,1,padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2,2)
            
            
        )
        self.conv_layer_4 = nn.Sequential(
            nn.Conv2d(64,128,3,1,padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2,2)
            
        )
        
        self.Neural_layer_1 = nn.Linear(128*4*4,2048) #128*4*4 for fully connected #pooling 128*8*8 #64*8*8 after 1 conv removal 
        self.Neural_layer_2 = nn.Linear(2048,1024)
        self.Neural_layer_3 = nn.Linear(1024,512)
        self.Neural_layer_4 = nn.Linear(512,5)
       
    def forward(self,x):
        x = self.conv_layer_1(x)
        x = self.conv_layer_2(x)
        x = self.conv_layer_3(x)
        x = self.conv_layer_4(x)
        x = x.view(-1,128*4*4)
        x = F.relu(self.Neural_layer_1(x))
        x = F.relu(self.Neural_layer_2(x))
        x = F.relu(self.Neural_layer_3(x))
        x = self.Neural_layer_4(x)
                
        return x

model = CNN()
print(model)

Epochs = 15
Learning_Rate = 0.001
criterion = nn.CrossEntropyLoss()#softmax is included in the nn for the last layer
optimizer = torch.optim.Adamax(model.parameters(),lr = Learning_Rate)#we are using adamax algo for optimization

def train_CNN_Model():
  training_loss=0
  correct_res=0
  size=0
  y_pred=[]
  y_true=[]

  for epoch in range(Epochs):
      for i, (images, labels) in enumerate(train_dataloader):
        
          res = model(images)
          #print(images.shape)
          optimizer.zero_grad()
          loss = criterion(res, labels)
          optimizer.zero_grad()
          loss.backward()
          optimizer.step()

          _, preds = torch.max(res, 1)
          training_loss += loss.item()
          correct_res += torch.sum(preds == labels.data)

          size += labels.size(0)

          acc = 100.0 * correct_res / size

          if (i+1) % len(train_dataloader) == 0:
              print (f'Epoch [{epoch+1}/{Epochs}], Loss: {loss.item():.4f}')
              print('accuracy is: {:.4f} '.format(acc))

  print('Finished Training')
  PATH = './cnn.pth'
  torch.save(model.state_dict(), PATH)

train_CNN_Model()
 
y_pred=[]
y_true=[]

def test_CNN_Model():
    with torch.no_grad():
      correct_res = 0
      size = 0
      for img, label in test_dataloader:
          result = model(img)

          _, preds = torch.max(result, 1)
          size += label.size(0)
          correct_res += (preds == label).sum().item()

          output = (torch.max(torch.exp(result), 1)[1]).data.cpu().numpy()
          y_pred.extend(output)

          label = label.data.cpu().numpy()
          y_true.extend(label)
  

      acc = (100.0 * correct_res) / size
      acc = "{:.2f}".format(acc)
      print(f'Accuracy of the network: {acc} %')

test_CNN_Model()
#metrics_and_scores(y_pred,y_true)
print(classification_report(y_true, y_pred, target_names=categories))

conf_mat=confusion_matrix(y_true,y_pred)  
df_conf_mat= pd.DataFrame(conf_mat, index = [i for i in categories],
                     columns = [i for i in categories])
plt.figure(figsize = (12,7))
fig=sn.heatmap(df_conf_mat, annot=True)
figure = fig.get_figure()
figure.savefig("Heatmap.png")

from google.colab import drive
drive.mount('/content/drive')

from PIL import Image
from pathlib import Path
chkPt = torch.load(Path('/content/cnn.pth'))
model.load_state_dict(chkPt)
trans = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.Resize(64),
    transforms.CenterCrop(64),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))
    ])

image = Image.open(Path("/content/drive/MyDrive/FINAL_DATASET/SurgicalMask/1151.png"))

input = trans(image)

input = input.view(1, 3, 64, 64)

output = model(input)

predict = int(torch.max(output.data, 1)[1].numpy())
print(predict)

if (predict == 0):
    print ('ClothMask')
if (predict == 1):
    print ('IncorrectMask')
if (predict == 2):
    print ('N95')
if (predict == 3):
    print ('SurgicalMask')
if (predict == 4):
    print ('WithoutMask')

